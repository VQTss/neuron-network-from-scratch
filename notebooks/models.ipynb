{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3208e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a6dd702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "X,y =  spiral_data(samples=100, classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8412a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "\n",
    "    # Layer initialization\n",
    "    def __init__(self,n_inputs, n_neurons):\n",
    "        self.weights = 0.01 * np.random.rand(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1,n_neurons))\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Calculate output values from inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0088e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU Activate\n",
    "class Activation_ReLU():\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Calculate output values from inputs\n",
    "        self.output = np.maximum(0, inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b64df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax activation\n",
    "class Activation_Softmax():\n",
    "    \n",
    "    # forward pass\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values =  np.exp(inputs - np.max(inputs,axis=1,keepdims=1))\n",
    "\n",
    "        # Normalized them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=1)\n",
    "\n",
    "        self.output = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687b9ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common loss class\n",
    "\n",
    "class Loss:\n",
    "\n",
    "    # Calculates the data and regularization losses\n",
    "    # given model output and ground truth values\n",
    "    def calculate(self,output, y):\n",
    "\n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output,y)\n",
    "\n",
    "        data_loss = np.mean(sample_losses)\n",
    "\n",
    "        return data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b985a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-entropy loss\n",
    "\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Probabilities for target values -\n",
    "        # only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[range(samples),y_true]\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped * y_true,axis=1)\n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82d2ec8",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36a3a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dense layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3242f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17b24f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create second Dense layer with 3 input features (as we take output\n",
    "# of previous layer here) and 3 output values\n",
    "dense2 = Layer_Dense(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49d6e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Softmax activation (to be used with Dense layer):\n",
    "activation2 = Activation_Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "597d49fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function\n",
    "loss_function = Loss_CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2545cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a forward pass of our training data through this layer\n",
    "dense1.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c6294ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform a forward pass through activation function\n",
    "# it takes the output of first dense layer here\n",
    "activation1.forward(dense1.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d03b6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a forward pass through second Dense layer\n",
    "# it takes outputs of activation function of first layer as inputs\n",
    "dense2.forward(activation1.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9473a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a forward pass through activation function\n",
    "# it takes the output of second dense layer here\n",
    "activation2.forward(dense2.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab8632fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.33333325 0.33333355 0.3333332 ]\n",
      " [0.33333316 0.33333376 0.33333313]\n",
      " [0.3333331  0.3333337  0.3333332 ]\n",
      " [0.33333302 0.33333385 0.3333331 ]]\n"
     ]
    }
   ],
   "source": [
    "# Let's see output of the first few samples:\n",
    "print(activation2.output[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c861ba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a forward pass through loss function\n",
    "# it takes the output of second dense layer here and returns loss\n",
    "loss = loss_function.calculate(activation2.output, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33bac3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0986115\n"
     ]
    }
   ],
   "source": [
    "# Print loss value\n",
    "print('loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "893bc11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333325, 0.33333355, 0.3333332 ],\n",
       "       [0.33333316, 0.33333376, 0.33333313],\n",
       "       [0.3333331 , 0.3333337 , 0.3333332 ],\n",
       "       [0.33333302, 0.33333385, 0.3333331 ],\n",
       "       [0.33333302, 0.3333343 , 0.33333275],\n",
       "       [0.3333328 , 0.33333436, 0.33333284],\n",
       "       [0.3333327 , 0.3333348 , 0.33333254],\n",
       "       [0.3333326 , 0.33333495, 0.33333248],\n",
       "       [0.33333254, 0.33333483, 0.33333263],\n",
       "       [0.33333242, 0.33333504, 0.33333254],\n",
       "       [0.33333278, 0.3333341 , 0.33333316],\n",
       "       [0.33333254, 0.33333442, 0.33333302],\n",
       "       [0.33333233, 0.33333504, 0.3333327 ],\n",
       "       [0.33333248, 0.3333345 , 0.33333308],\n",
       "       [0.33333242, 0.3333345 , 0.33333305],\n",
       "       [0.3333331 , 0.3333336 , 0.33333325],\n",
       "       [0.33333224, 0.3333348 , 0.33333296],\n",
       "       [0.33333257, 0.33333433, 0.3333331 ],\n",
       "       [0.33333197, 0.3333354 , 0.33333263],\n",
       "       [0.33333144, 0.33333737, 0.33333117],\n",
       "       [0.3333332 , 0.33333355, 0.33333328],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333233, 0.33333465, 0.33333302],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.333332  , 0.33333507, 0.33333293],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333284, 0.33333403, 0.3333332 ],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333287, 0.33333617, 0.333331  ],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.333333  , 0.33333543, 0.33333158],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333325, 0.33333367, 0.33333302],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333275, 0.33333683, 0.3333304 ],\n",
       "       [0.3333331 , 0.33333477, 0.33333218],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333263, 0.3333376 , 0.3333298 ],\n",
       "       [0.33333194, 0.33333975, 0.33332828],\n",
       "       [0.3333324 , 0.33333907, 0.33332857],\n",
       "       [0.33333123, 0.3333413 , 0.3333275 ],\n",
       "       [0.33333248, 0.3333385 , 0.33332905],\n",
       "       [0.33333185, 0.33334032, 0.3333279 ],\n",
       "       [0.3333321 , 0.33333984, 0.33332804],\n",
       "       [0.3333307 , 0.33334252, 0.33332676],\n",
       "       [0.33333135, 0.33334148, 0.33332723],\n",
       "       [0.33333245, 0.33333868, 0.33332887],\n",
       "       [0.33332813, 0.33334652, 0.3333254 ],\n",
       "       [0.3333287 , 0.33334598, 0.33332533],\n",
       "       [0.33333123, 0.33334196, 0.33332682],\n",
       "       [0.33332705, 0.33334696, 0.33332598],\n",
       "       [0.33332825, 0.33334678, 0.3333249 ],\n",
       "       [0.33332685, 0.33334738, 0.3333257 ],\n",
       "       [0.33332717, 0.33334473, 0.3333281 ],\n",
       "       [0.33332676, 0.33334652, 0.33332673],\n",
       "       [0.33332846, 0.3333403 , 0.33333123],\n",
       "       [0.33332685, 0.33334866, 0.33332452],\n",
       "       [0.3333276 , 0.33334267, 0.3333297 ],\n",
       "       [0.33332637, 0.33334726, 0.33332634],\n",
       "       [0.3333263 , 0.33334744, 0.3333263 ],\n",
       "       [0.3333267 , 0.3333453 , 0.33332798],\n",
       "       [0.3333275 , 0.33334258, 0.33332995],\n",
       "       [0.33332878, 0.33333927, 0.3333319 ],\n",
       "       [0.3333265 , 0.33334565, 0.33332786],\n",
       "       [0.33333212, 0.33333495, 0.33333296],\n",
       "       [0.33333135, 0.33333594, 0.33333272],\n",
       "       [0.33332664, 0.3333446 , 0.3333287 ],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333248, 0.3333345 , 0.33333308],\n",
       "       [0.33333018, 0.33333746, 0.33333236],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.3333333 , 0.3333336 , 0.33333313],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333325, 0.33333403, 0.33333278],\n",
       "       [0.33333322, 0.33333397, 0.3333328 ],\n",
       "       [0.3333332 , 0.33333433, 0.3333325 ],\n",
       "       [0.33333322, 0.33333403, 0.33333278],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333278, 0.33333528, 0.33333194],\n",
       "       [0.33333325, 0.3333337 , 0.33333302],\n",
       "       [0.33333308, 0.3333348 , 0.33333212],\n",
       "       [0.33333287, 0.33333528, 0.3333318 ],\n",
       "       [0.33333313, 0.33333454, 0.33333233],\n",
       "       [0.33333275, 0.33333564, 0.33333156],\n",
       "       [0.33333233, 0.3333365 , 0.3333312 ],\n",
       "       [0.33333257, 0.3333362 , 0.33333126],\n",
       "       [0.3333331 , 0.33333462, 0.33333224],\n",
       "       [0.33333218, 0.33333695, 0.3333308 ],\n",
       "       [0.33333132, 0.33333814, 0.3333305 ],\n",
       "       [0.3333327 , 0.33333623, 0.3333311 ],\n",
       "       [0.33333188, 0.3333377 , 0.3333304 ],\n",
       "       [0.3333319 , 0.33333775, 0.33333033],\n",
       "       [0.33333093, 0.33333796, 0.33333117],\n",
       "       [0.33333075, 0.33333915, 0.3333301 ],\n",
       "       [0.3333307 , 0.3333394 , 0.33332995],\n",
       "       [0.3333312 , 0.33333915, 0.33332965],\n",
       "       [0.33333042, 0.3333394 , 0.33333015],\n",
       "       [0.33333063, 0.33334   , 0.33332938],\n",
       "       [0.33333024, 0.33333993, 0.33332986],\n",
       "       [0.3333302 , 0.33334044, 0.33332932],\n",
       "       [0.33333048, 0.33333826, 0.33333132],\n",
       "       [0.33333048, 0.3333381 , 0.33333144],\n",
       "       [0.33332998, 0.33333975, 0.33333024],\n",
       "       [0.33333054, 0.33333763, 0.3333318 ],\n",
       "       [0.33332968, 0.333341  , 0.33332932],\n",
       "       [0.3333296 , 0.33334145, 0.33332896],\n",
       "       [0.33333114, 0.33333623, 0.33333266],\n",
       "       [0.333331  , 0.3333364 , 0.33333263],\n",
       "       [0.33333188, 0.33333528, 0.3333329 ],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333302, 0.33333376, 0.33333322],\n",
       "       [0.33333042, 0.33333722, 0.33333233],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.3333303 , 0.3333374 , 0.3333323 ],\n",
       "       [0.33333188, 0.33333528, 0.3333329 ],\n",
       "       [0.33333296, 0.33333382, 0.33333322],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333242, 0.33333457, 0.33333305],\n",
       "       [0.33333263, 0.33333427, 0.3333331 ],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333316, 0.3333343 , 0.3333325 ],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333308, 0.33333495, 0.333332  ],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.3333328 , 0.3333365 , 0.33333066],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333248, 0.33333853, 0.333329  ],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.3333332 , 0.33333412, 0.33333266],\n",
       "       [0.33333284, 0.33333632, 0.33333087],\n",
       "       [0.3333323 , 0.33333942, 0.33332825],\n",
       "       [0.33333245, 0.3333388 , 0.3333288 ],\n",
       "       [0.33333308, 0.3333348 , 0.3333321 ],\n",
       "       [0.3333323 , 0.3333394 , 0.33332825],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33332807, 0.33334863, 0.3333233 ],\n",
       "       [0.33333257, 0.33333793, 0.33332947],\n",
       "       [0.33333203, 0.3333412 , 0.3333268 ],\n",
       "       [0.3333278 , 0.33334935, 0.33332288],\n",
       "       [0.33332974, 0.33334625, 0.33332404],\n",
       "       [0.33332503, 0.3333502 , 0.33332476],\n",
       "       [0.3333302 , 0.33334547, 0.33332428],\n",
       "       [0.3333252 , 0.33335245, 0.33332238],\n",
       "       [0.33332527, 0.33335263, 0.3333221 ],\n",
       "       [0.33332744, 0.3333504 , 0.33332217],\n",
       "       [0.33332455, 0.3333512 , 0.33332422],\n",
       "       [0.3333245 , 0.33335292, 0.3333226 ],\n",
       "       [0.33332518, 0.3333479 , 0.33332697],\n",
       "       [0.33332565, 0.33334613, 0.33332822],\n",
       "       [0.33333024, 0.3333374 , 0.3333324 ],\n",
       "       [0.33332816, 0.33334008, 0.33333173],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333322, 0.3333335 , 0.33333325],\n",
       "       [0.33333325, 0.33333346, 0.3333333 ],\n",
       "       [0.33333316, 0.33333355, 0.33333328],\n",
       "       [0.33333313, 0.3333336 , 0.33333328],\n",
       "       [0.33333287, 0.33333433, 0.33333284],\n",
       "       [0.33333302, 0.3333338 , 0.33333322],\n",
       "       [0.33333284, 0.3333341 , 0.33333308],\n",
       "       [0.33333308, 0.3333337 , 0.33333325],\n",
       "       [0.333333  , 0.33333382, 0.33333322],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333322, 0.33333346, 0.33333328],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333302, 0.33333376, 0.33333325],\n",
       "       [0.33333287, 0.33333397, 0.3333332 ],\n",
       "       [0.33333325, 0.33333346, 0.3333333 ],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333313, 0.33333462, 0.33333224],\n",
       "       [0.3333328 , 0.3333365 , 0.3333307 ],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.333333  , 0.3333353 , 0.33333167],\n",
       "       [0.3333328 , 0.33333635, 0.33333078],\n",
       "       [0.33333325, 0.3333338 , 0.33333296],\n",
       "       [0.33333305, 0.33333492, 0.33333197],\n",
       "       [0.33333287, 0.33333614, 0.333331  ],\n",
       "       [0.33333284, 0.3333363 , 0.33333087],\n",
       "       [0.33333275, 0.3333368 , 0.33333042],\n",
       "       [0.33333325, 0.33333376, 0.333333  ],\n",
       "       [0.33333004, 0.3333423 , 0.33332768],\n",
       "       [0.33332977, 0.3333427 , 0.3333275 ],\n",
       "       [0.3333326 , 0.33333784, 0.3333296 ],\n",
       "       [0.33333275, 0.33333683, 0.33333042],\n",
       "       [0.3333295 , 0.3333434 , 0.3333271 ],\n",
       "       [0.333331  , 0.33334124, 0.33332774],\n",
       "       [0.3333293 , 0.33334383, 0.33332685],\n",
       "       [0.33332962, 0.33334357, 0.33332682],\n",
       "       [0.33332828, 0.33334443, 0.33332723],\n",
       "       [0.33332816, 0.33334434, 0.33332747],\n",
       "       [0.33332908, 0.33334455, 0.33332637],\n",
       "       [0.33332983, 0.33334363, 0.33332655],\n",
       "       [0.33332977, 0.33334383, 0.33332643],\n",
       "       [0.3333281 , 0.3333431 , 0.33332878],\n",
       "       [0.3333283 , 0.33334583, 0.33332592],\n",
       "       [0.3333276 , 0.33334553, 0.33332688],\n",
       "       [0.3333275 , 0.3333455 , 0.33332697],\n",
       "       [0.33332792, 0.33334315, 0.33332896],\n",
       "       [0.33332786, 0.3333467 , 0.33332542],\n",
       "       [0.3333288 , 0.33334002, 0.33333117],\n",
       "       [0.3333298 , 0.33333796, 0.33333224],\n",
       "       [0.3333293 , 0.3333386 , 0.3333321 ],\n",
       "       [0.33332884, 0.33333963, 0.3333315 ],\n",
       "       [0.33333   , 0.33333766, 0.3333323 ],\n",
       "       [0.33333114, 0.33333617, 0.33333266],\n",
       "       [0.33332673, 0.33334798, 0.3333253 ],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333275, 0.33333415, 0.33333313],\n",
       "       [0.3333304 , 0.3333372 , 0.33333242],\n",
       "       [0.3333316 , 0.33333558, 0.33333278],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33332887, 0.33333918, 0.33333197],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333233, 0.33333933, 0.33332834],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333284, 0.33333632, 0.33333084],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333296, 0.33333546, 0.33333153],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333278, 0.3333367 , 0.3333305 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation2.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5cb9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuray from output activation2 and target\n",
    "# Calculate values along first axis\n",
    "predictions = np.argmax(activation2.output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32732d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.36)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(y.shape) == 2:\n",
    "    y = np.argmax(y,axis=1)\n",
    "\n",
    "accuracy = np.mean(predictions == y)\n",
    "\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
