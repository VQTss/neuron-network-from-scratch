{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e102f88a",
   "metadata": {},
   "source": [
    "# Calculating Network Error with Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb0b31c",
   "metadata": {},
   "source": [
    "## Categorical Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4523af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9363762",
   "metadata": {},
   "source": [
    "<img src='./assets/cross-functions.png' width=700 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "980de7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_output = [0.7, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c245c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "target_output = [1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "571c609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = - (\n",
    "    math.log(softmax_output[0]) * target_output[0] + math.log(softmax_output[1]) * target_output[1] + math.log(softmax_output[2]) * target_output[2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9715edf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35667494393873245"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12942a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "710381ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.6486586255873816)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 5.2\n",
    "np.log(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd742d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.199999999999999)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.e ** np.log(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23376859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilities for 3 samples\n",
    "softmax_outputs = np.array([[0.7, 0.1, 0.2],\n",
    "[0.1, 0.5, 0.4],\n",
    "[0.02, 0.9, 0.08]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccb79825",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_targets = [0, 1, 1] # dog, cat, cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5591e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, array([0.7, 0.1, 0.2])),\n",
       " (1, array([0.1, 0.5, 0.4])),\n",
       " (1, array([0.02, 0.9 , 0.08])))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(zip(class_targets, softmax_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f48d848c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value targ_idx 0\n",
      "value distribution [0.7 0.1 0.2]\n",
      "0.7\n",
      "value targ_idx 1\n",
      "value distribution [0.1 0.5 0.4]\n",
      "0.5\n",
      "value targ_idx 1\n",
      "value distribution [0.02 0.9  0.08]\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "for targ_idx, distribution in zip(class_targets, softmax_outputs):\n",
    "    print(f'value targ_idx {targ_idx}')\n",
    "    print(f'value distribution {distribution}')\n",
    "    print(distribution[targ_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b5c80f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7, 0.5, 0.9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_outputs[[0, 1, 2], class_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96a33c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_outputs = np.array([[0.7, 0.1, 0.2],\n",
    "[0.1, 0.5, 0.4],\n",
    "[0.02, 0.9, 0.08]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8eabeed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(softmax_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0703db21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7, 0.5, 0.9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_outputs[range(len(softmax_outputs)), class_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "910b0e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35667494, 0.69314718, 0.10536052])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(softmax_outputs[range(len(softmax_outputs)), class_targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ed5610d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38506088005216804\n"
     ]
    }
   ],
   "source": [
    "neg_log = -np.log(softmax_outputs[range(len(softmax_outputs)), class_targets])\n",
    "average_loss = np.mean(neg_log)\n",
    "print(average_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e95ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_outputs = np.array([[0.7, 0.1, 0.2],\n",
    "                            [0.1, 0.5, 0.4],\n",
    "                            [0.02, 0.9, 0.08]])\n",
    "class_targets = np.array([[1, 0, 0],\n",
    "                            [0, 1, 0],\n",
    "                            [0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5c893f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c75db973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1 , 0.1 , 0.02],\n",
       "       [0.7 , 0.5 , 0.02],\n",
       "       [0.7 , 0.5 , 0.02]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_outputs[range(len(softmax_outputs)),class_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8773997b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7 0.5 0.9]\n"
     ]
    }
   ],
   "source": [
    "# Probabilities for target values -\n",
    "# only if categorical labels\n",
    "if len(class_targets.shape) == 1:\n",
    "    correct_confidences = softmax_outputs[range(len(softmax_outputs)),class_targets]\n",
    "    print(correct_confidences)\n",
    "# Mask values - only for one-hot encoded labels\n",
    "elif len(class_targets.shape) == 2:\n",
    "    correct_confidences = np.sum(softmax_outputs * class_targets,axis=1)\n",
    "    print(correct_confidences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988bf712",
   "metadata": {},
   "source": [
    "<img src='./assets/explain_loss_1.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169a66e9",
   "metadata": {},
   "source": [
    "<img src='./assets/explain_loss_2.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdfcbff",
   "metadata": {},
   "source": [
    "<img src='./assets/exlpain_loss_3.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9f33ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35667494, 0.69314718, 0.10536052])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Losses \n",
    "neg_log = -np.log(correct_confidences)\n",
    "neg_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f4ddbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.38506088005216804)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_loss = np.mean(neg_log)\n",
    "average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b607250e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.e**(-np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5e10a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1t/vjpby4gn7yn974d6rw866wp00000gn/T/ipykernel_3130/2869289095.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  -np.log(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(inf)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eda960",
   "metadata": {},
   "source": [
    "We read it as the limit of a natural logarithm of x, with x approaching 0 from a positive (it is impossible to calculate the natural logarithm of a negative value) equals negative infinity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba11684",
   "metadata": {},
   "source": [
    "<img src='./assets/error_loss_log.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58db64f2",
   "metadata": {},
   "source": [
    "This will prevent loss from being exactly 0, making it a very small value instead, but won’t make\n",
    "it a negative value and won’t bias overall loss towards 1. Within our code and using numpy, we’ll\n",
    "accomplish that using np.clip() method:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba12c3",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/numpy-clip-in-python/\n",
    "\n",
    "y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6363b71",
   "metadata": {},
   "source": [
    "## The Categorical Cross-Entropy Loss Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bd9516",
   "metadata": {},
   "source": [
    "# Common loss class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17513e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss: # parent class\n",
    "    # Calculates the data and regularization losses\n",
    "    # Given model output and ground truth values (y)\n",
    "\n",
    "    def calculate(self, output,y):\n",
    "\n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output,y)\n",
    "\n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "\n",
    "        return data_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b66f07b",
   "metadata": {},
   "source": [
    "# Cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44364308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "    \n",
    "    # forward pass\n",
    "    # y_pred is softmax output\n",
    "    # y_true is ground true\n",
    "    def forward(self, y_pred,y_true):\n",
    "\n",
    "        # Number of sample in a batch\n",
    "        samples = len(y_pred)\n",
    "\n",
    "        # Clip data to prevent divsion by 0\n",
    "        # Clip both sides to not drag mean toward any values\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        # Probabilities for target values -\n",
    "        # only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[range(samples),y_true]\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped * y_true,axis=1)\n",
    "        \n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c2f4f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38506088005216804\n"
     ]
    }
   ],
   "source": [
    "loss_function = Loss_CategoricalCrossentropy()\n",
    "loss = loss_function.calculate(softmax_outputs, class_targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f926c912",
   "metadata": {},
   "source": [
    "## Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee8d047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilities of 3 samples\n",
    "softmax_outputs = np.array([[0.7, 0.2, 0.1],\n",
    "[0.5, 0.1, 0.4],\n",
    "[0.02, 0.9, 0.08]])\n",
    "# Target (ground-truth) labels for 3 samples\n",
    "class_targets = np.array([0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a81096",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/numpy-argmax-python/\n",
    "\n",
    "Return indices max elements in arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2d6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate values along second axis ( axis of index 1 )\n",
    "predictions = np.argmax(softmax_outputs , axis=1) \n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "782ce683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6666666666666666)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If targets are one-hot encoded - convert them\n",
    "if len(class_targets.shape) == 2:\n",
    "    class_targets = np.argmax(class_targets, axis=1)\n",
    "\n",
    "# True evaluates to 1 and False to 0\n",
    "accuracy = np.mean(class_targets == predictions)\n",
    "\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
